{
      "annotations": {
         "list": [ ]
      },
      "editable": false,
      "id": null,
      "links": [
         {
            "keepTime": true,
            "title": "TensorFlow logs",
            "type": "link",
            "url": "/d/tensorflow-logs"
         },
         {
            "asDropdown": true,
            "includeVars": true,
            "keepTime": true,
            "tags": [
               "tensorflow"
            ],
            "title": "All dashboards",
            "type": "dashboards"
         }
      ],
      "panels": [
         {
            "collapsed": false,
            "gridPos": {
               "h": 1,
               "w": 0,
               "x": 0,
               "y": 0
            },
            "id": 1,
            "panels": [ ],
            "title": "Model",
            "type": "row"
         },
         {
            "datasource": {
               "type": "prometheus",
               "uid": "${prometheus_datasource}"
            },
            "description": "Rate of requests over time for the selected model. Grouped by statuses.",
            "fieldConfig": {
               "defaults": {
                  "custom": {
                     "fillOpacity": 0,
                     "gradientMode": "opacity",
                     "lineInterpolation": "linear",
                     "lineWidth": 2,
                     "showPoints": "never",
                     "spanNulls": false
                  },
                  "unit": "reqps"
               }
            },
            "gridPos": {
               "h": 8,
               "w": 24,
               "x": 0,
               "y": 1
            },
            "id": 2,
            "options": {
               "legend": {
                  "calcs": [ ],
                  "displayMode": "list"
               },
               "tooltip": {
                  "mode": "multi",
                  "sort": "desc"
               }
            },
            "pluginVersion": "v11.0.0",
            "targets": [
               {
                  "datasource": {
                     "type": "prometheus",
                     "uid": "${prometheus_datasource}"
                  },
                  "expr": "rate(:tensorflow:serving:request_count{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])",
                  "format": "time_series",
                  "instant": false,
                  "legendFormat": "{{ instance }} - {{ model_name }}",
                  "refId": "Model request rate"
               }
            ],
            "title": "Model request rate",
            "type": "timeseries"
         },
         {
            "datasource": {
               "type": "prometheus",
               "uid": "${prometheus_datasource}"
            },
            "description": "Average request latency of predict requests for the selected model.",
            "fieldConfig": {
               "defaults": {
                  "custom": {
                     "fillOpacity": 0,
                     "gradientMode": "opacity",
                     "lineInterpolation": "linear",
                     "lineWidth": 2,
                     "showPoints": "never",
                     "spanNulls": false
                  },
                  "unit": "µs"
               }
            },
            "gridPos": {
               "h": 8,
               "w": 12,
               "x": 0,
               "y": 9
            },
            "id": 3,
            "options": {
               "legend": {
                  "calcs": [ ],
                  "displayMode": "list"
               },
               "tooltip": {
                  "mode": "multi",
                  "sort": "desc"
               }
            },
            "pluginVersion": "v11.0.0",
            "targets": [
               {
                  "datasource": {
                     "type": "prometheus",
                     "uid": "${prometheus_datasource}"
                  },
                  "expr": "increase(:tensorflow:serving:request_latency_sum{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])/increase(:tensorflow:serving:request_latency_count{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])",
                  "format": "time_series",
                  "instant": false,
                  "legendFormat": "{{ instance }} - {{ model_name }}",
                  "refId": "Model predict request latency"
               }
            ],
            "title": "Model predict request latency",
            "type": "timeseries"
         },
         {
            "datasource": {
               "type": "prometheus",
               "uid": "${prometheus_datasource}"
            },
            "description": "Average runtime latency to fulfill a predict request for the selected model.",
            "fieldConfig": {
               "defaults": {
                  "custom": {
                     "fillOpacity": 0,
                     "gradientMode": "opacity",
                     "lineInterpolation": "linear",
                     "lineWidth": 2,
                     "showPoints": "never",
                     "spanNulls": false
                  },
                  "unit": "µs"
               }
            },
            "gridPos": {
               "h": 8,
               "w": 12,
               "x": 12,
               "y": 9
            },
            "id": 4,
            "options": {
               "legend": {
                  "calcs": [ ],
                  "displayMode": "list"
               },
               "tooltip": {
                  "mode": "multi",
                  "sort": "desc"
               }
            },
            "pluginVersion": "v11.0.0",
            "targets": [
               {
                  "datasource": {
                     "type": "prometheus",
                     "uid": "${prometheus_datasource}"
                  },
                  "expr": "increase(:tensorflow:serving:runtime_latency_sum{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])/increase(:tensorflow:serving:runtime_latency_count{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])",
                  "format": "time_series",
                  "instant": false,
                  "legendFormat": "{{ instance }} - {{ model_name }}",
                  "refId": "Model predict runtime latency"
               }
            ],
            "title": "Model predict runtime latency",
            "type": "timeseries"
         },
         {
            "collapsed": false,
            "gridPos": {
               "h": 1,
               "w": 0,
               "x": 0,
               "y": 17
            },
            "id": 5,
            "panels": [ ],
            "title": "Serving overview",
            "type": "row"
         },
         {
            "datasource": {
               "type": "prometheus",
               "uid": "${prometheus_datasource}"
            },
            "description": "Number of times TensorFlow Serving has created a new client graph.",
            "fieldConfig": {
               "defaults": {
                  "custom": {
                     "fillOpacity": 0,
                     "gradientMode": "opacity",
                     "lineInterpolation": "linear",
                     "lineWidth": 2,
                     "showPoints": "never",
                     "spanNulls": false
                  },
                  "unit": "none"
               }
            },
            "gridPos": {
               "h": 8,
               "w": 12,
               "x": 0,
               "y": 18
            },
            "id": 6,
            "options": {
               "legend": {
                  "calcs": [ ],
                  "displayMode": "list"
               },
               "tooltip": {
                  "mode": "multi",
                  "sort": "desc"
               }
            },
            "pluginVersion": "v11.0.0",
            "targets": [
               {
                  "datasource": {
                     "type": "prometheus",
                     "uid": "${prometheus_datasource}"
                  },
                  "expr": "increase(:tensorflow:core:graph_build_calls{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])",
                  "format": "time_series",
                  "instant": false,
                  "legendFormat": "{{ instance }}",
                  "refId": "Graph build calls"
               }
            ],
            "title": "Graph build calls",
            "type": "timeseries"
         },
         {
            "datasource": {
               "type": "prometheus",
               "uid": "${prometheus_datasource}"
            },
            "description": "Number of graph executions.",
            "fieldConfig": {
               "defaults": {
                  "custom": {
                     "fillOpacity": 0,
                     "gradientMode": "opacity",
                     "lineInterpolation": "linear",
                     "lineWidth": 2,
                     "showPoints": "never",
                     "spanNulls": false
                  },
                  "unit": "none"
               }
            },
            "gridPos": {
               "h": 8,
               "w": 12,
               "x": 12,
               "y": 18
            },
            "id": 7,
            "options": {
               "legend": {
                  "calcs": [ ],
                  "displayMode": "list"
               },
               "tooltip": {
                  "mode": "multi",
                  "sort": "desc"
               }
            },
            "pluginVersion": "v11.0.0",
            "targets": [
               {
                  "datasource": {
                     "type": "prometheus",
                     "uid": "${prometheus_datasource}"
                  },
                  "expr": "increase(:tensorflow:core:graph_runs{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])",
                  "format": "time_series",
                  "instant": false,
                  "legendFormat": "{{ instance }}",
                  "refId": "Graph runs"
               }
            ],
            "title": "Graph runs",
            "type": "timeseries"
         },
         {
            "datasource": {
               "type": "prometheus",
               "uid": "${prometheus_datasource}"
            },
            "description": "Amount of time Tensorflow has spent creating new client graphs.",
            "fieldConfig": {
               "defaults": {
                  "custom": {
                     "fillOpacity": 0,
                     "gradientMode": "opacity",
                     "lineInterpolation": "linear",
                     "lineWidth": 2,
                     "showPoints": "never",
                     "spanNulls": false
                  },
                  "unit": "µs"
               }
            },
            "gridPos": {
               "h": 8,
               "w": 12,
               "x": 0,
               "y": 26
            },
            "id": 8,
            "options": {
               "legend": {
                  "calcs": [ ],
                  "displayMode": "list"
               },
               "tooltip": {
                  "mode": "multi",
                  "sort": "desc"
               }
            },
            "pluginVersion": "v11.0.0",
            "targets": [
               {
                  "datasource": {
                     "type": "prometheus",
                     "uid": "${prometheus_datasource}"
                  },
                  "expr": "increase(:tensorflow:core:graph_build_time_usecs{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])/increase(:tensorflow:core:graph_build_calls{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])",
                  "format": "time_series",
                  "instant": false,
                  "legendFormat": "{{ instance }}",
                  "refId": "Graph build time"
               }
            ],
            "title": "Graph build time",
            "type": "timeseries"
         },
         {
            "datasource": {
               "type": "prometheus",
               "uid": "${prometheus_datasource}"
            },
            "description": "Amount of time spent executing graphs.",
            "fieldConfig": {
               "defaults": {
                  "custom": {
                     "fillOpacity": 0,
                     "gradientMode": "opacity",
                     "lineInterpolation": "linear",
                     "lineWidth": 2,
                     "showPoints": "never",
                     "spanNulls": false
                  },
                  "unit": "µs"
               }
            },
            "gridPos": {
               "h": 8,
               "w": 12,
               "x": 12,
               "y": 26
            },
            "id": 9,
            "options": {
               "legend": {
                  "calcs": [ ],
                  "displayMode": "list"
               },
               "tooltip": {
                  "mode": "multi",
                  "sort": "desc"
               }
            },
            "pluginVersion": "v11.0.0",
            "targets": [
               {
                  "datasource": {
                     "type": "prometheus",
                     "uid": "${prometheus_datasource}"
                  },
                  "expr": "increase(:tensorflow:core:graph_run_time_usecs{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])/increase(:tensorflow:core:graph_runs{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\",instance=~\"$instance\"}[$__rate_interval])",
                  "format": "time_series",
                  "instant": false,
                  "legendFormat": "{{ instance }}",
                  "refId": "Graph run time"
               }
            ],
            "title": "Graph run time",
            "type": "timeseries"
         }
      ],
      "refresh": "30s",
      "schemaVersion": 39,
      "tags": [
         "tensorflow"
      ],
      "templating": {
         "list": [
            {
               "label": "Prometheus data source",
               "name": "prometheus_datasource",
               "query": "prometheus",
               "regex": "(?!grafanacloud-usage|grafanacloud-ml-metrics).+",
               "type": "datasource"
            },
            {
               "allValue": ".+",
               "datasource": {
                  "type": "prometheus",
                  "uid": "${prometheus_datasource}"
               },
               "includeAll": true,
               "label": "Job",
               "multi": true,
               "name": "job",
               "query": "label_values(:tensorflow:serving:request_count{job=~\"integrations/tensorflow\"}, job)",
               "refresh": 2,
               "sort": 1,
               "type": "query"
            },
            {
               "allValue": ".*",
               "datasource": {
                  "type": "prometheus",
                  "uid": "${prometheus_datasource}"
               },
               "includeAll": true,
               "label": "Cluster",
               "multi": true,
               "name": "cluster",
               "query": "label_values(:tensorflow:serving:request_count{job=~\"integrations/tensorflow\",job=~\"$job\"}, cluster)",
               "refresh": 2,
               "sort": 1,
               "type": "query"
            },
            {
               "allValue": ".+",
               "datasource": {
                  "type": "prometheus",
                  "uid": "${prometheus_datasource}"
               },
               "includeAll": false,
               "label": "Instance",
               "multi": false,
               "name": "instance",
               "query": "label_values(:tensorflow:serving:request_count{job=~\"integrations/tensorflow\",job=~\"$job\",cluster=~\"$cluster\"}, instance)",
               "refresh": 2,
               "sort": 1,
               "type": "query"
            },
            {
               "hide": 2,
               "label": "Loki data source",
               "name": "loki_datasource",
               "query": "loki",
               "regex": "(?!grafanacloud.+usage-insights|grafanacloud.+alert-state-history).+",
               "type": "datasource"
            }
         ]
      },
      "time": {
         "from": "now-30m",
         "to": "now"
      },
      "timezone": "default",
      "title": "TensorFlow overview",
      "uid": "tensorflow_overview"
   }